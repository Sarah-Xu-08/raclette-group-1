{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "125803ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as io\n",
    "# from matplotlib import pyplot as plt\n",
    "import mne\n",
    "# from mne.minimum_norm import read_inverse_operator, compute_source_psd_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a23f33a",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55e3bb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load files\n",
    "data_dir = 'C:/Users/Lenovo/Desktop/NMA2022/Project/fingerflex 9 patients data/fingerflex/data/'\n",
    "pat = 'bp'\n",
    "alldat = io.loadmat(data_dir + '/' + pat + '/' + pat +'_fingerflex.mat')\n",
    "allresp = io.loadmat(data_dir + '/' + pat + '/' + pat +'_stim.mat')\n",
    "alldat['resp'] = allresp['stim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dca8df4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'MATLAB 5.0 MAT-file, Platform: MACI64, Created on: Mon Jan  4 09:05:12 2016'\n",
      "1.0\n",
      "[]\n",
      "data: <class 'numpy.ndarray'> (610040, 46)\n",
      "elec_regions: <class 'numpy.ndarray'> (46, 1)\n",
      "flex: <class 'numpy.ndarray'> (610040, 5)\n",
      "brain: <class 'numpy.ndarray'> (1, 1)\n",
      "locs: <class 'numpy.ndarray'> (46, 3)\n",
      "cue: <class 'numpy.ndarray'> (610040, 1)\n",
      "response: <class 'numpy.ndarray'> (610040, 1)\n"
     ]
    }
   ],
   "source": [
    "#print data shape\n",
    "print(alldat['__header__'])\n",
    "print(alldat['__version__'])\n",
    "print(alldat['__globals__'])\n",
    "print('data:', type(alldat['data']), alldat['data'].shape)\n",
    "print('elec_regions:', type(alldat['elec_regions']),alldat['elec_regions'].shape)\n",
    "print('flex:', type(alldat['flex']),alldat['flex'].shape)\n",
    "print('brain:', type(alldat['brain']),alldat['brain'].shape)\n",
    "print('locs:', type(alldat['locs']),alldat['locs'].shape)\n",
    "print('cue:', type(alldat['cue']),alldat['cue'].shape)\n",
    "print('response:', type(alldat['resp']),alldat['resp'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8be601",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nilearn --quiet\n",
    "!pip install nimare --quiet\n",
    "\n",
    "from nilearn import plotting\n",
    "from nimare import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597b9acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "locs = alldat['locs']\n",
    "view = plotting.view_markers(utils.tal2mni(locs),\n",
    "                             marker_labels=['%d'%k for k in np.arange(locs.shape[0])],\n",
    "                             marker_color='purple',\n",
    "                             marker_size=5)\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5057f4ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=46, n_times=610040\n",
      "    Range : 0 ... 610039 =      0.000 ...   610.039 secs\n",
      "Ready.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>0 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>46 ECoG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>1000.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>500.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "</table>"
      ],
      "text/plain": [
       "<Info | 7 non-empty values\n",
       " bads: []\n",
       " ch_names: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, ...\n",
       " chs: 46 ECoG\n",
       " custom_ref_applied: False\n",
       " highpass: 0.0 Hz\n",
       " lowpass: 500.0 Hz\n",
       " meas_date: unspecified\n",
       " nchan: 46\n",
       " projs: []\n",
       " sfreq: 1000.0 Hz\n",
       ">"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_freq = 1000  # in Hertz\n",
    "elect_region  =alldat['elec_regions']\n",
    "n_channels = len(elect_region)\n",
    "ch_types = 'ecog'\n",
    "ecog = alldat['data'].T\n",
    "\n",
    "info = mne.create_info(n_channels, ch_types = 'ecog', sfreq = sampling_freq)\n",
    "raw = mne.io.RawArray(ecog, info)\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74addb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up high-pass filter at 1 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal highpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Filter length: 3301 samples (3.301 sec)\n",
      "\n",
      "Setting up band-stop filter from 59 - 61 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 59.35\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 59.10 Hz)\n",
      "- Upper passband edge: 60.65 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 60.90 Hz)\n",
      "- Filter length: 6601 samples (6.601 sec)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#filter\n",
    "raw_filter = raw.copy().filter(l_freq=1., h_freq=None, picks='ecog') #1-200Hz\n",
    "raw_notch = raw_filter.copy().notch_filter(freqs=60, picks='ecog') # 60Hz\n",
    "# raw_downsampled = raw_notch.copy().resample(sfreq=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9633cb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_notch.pick(picks='all')\n",
    "# dict_r=ecog(1000) scalings=dict_r\n",
    "# raw_notch.plot()\n",
    "# plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8dfbd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 610040)\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "new_ecog = raw_notch.get_data()\n",
    "print(new_ecog.shape)\n",
    "ecog = new_ecog\n",
    "elect_region = alldat['elec_regions']\n",
    "print(len(ecog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b91c05e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5], dtype=uint8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exclude resp=-1, -2\n",
    "resp = alldat['resp']\n",
    "resp[resp == -1] = 0\n",
    "resp[resp == -2] = 0\n",
    "\n",
    "cue = alldat['cue']\n",
    "np.unique(cue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193d60ed",
   "metadata": {},
   "source": [
    "# Trails extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2868ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trails extraction (based on the one-to-one corresponding relation of each response and stimuli)\n",
    "def trail_extract(cue, resp):\n",
    "\n",
    "  for i in range(0, len(cue)):\n",
    "\n",
    "    if i == 0:\n",
    "      cue_mat = np.array([cue[0,0],0,0])\n",
    "      resp_mat = np.array([resp[0,0],0])\n",
    "      \n",
    "    elif cue[i] != cue[i-1] and cue[i] != 0:\n",
    "      last_cue = np.array([cue[i,0],i,i+4000])\n",
    "\n",
    "      if i+4000 < len(resp):\n",
    "\n",
    "        for t in range(i,i+2000):\n",
    "\n",
    "          if resp[i] != 0:\n",
    "            if resp[t] != resp[t-1] and resp[t] != 0:\n",
    "              this_resp = np.array([resp[t,0], t])\n",
    "              resp_mat = np.vstack((resp_mat, this_resp))   \n",
    "              cue_mat = np.vstack((cue_mat, last_cue))\n",
    "\n",
    "              break\n",
    "            elif resp[t] == 0 and (not np.any(resp[t:i+2000])):\n",
    "              for t_a in range(i+2000,i+4000):\n",
    "                if resp[t_a] != 0:\n",
    "                  this_resp = np.array([resp[t_a,0], t-a])\n",
    "                  resp_mat = np.vstack((resp_mat, this_resp))\n",
    "                  cue_mat = np.vstack((cue_mat, last_cue))   \n",
    "\n",
    "                break\n",
    "              break\n",
    "\n",
    "          else:\n",
    "            if resp[t] != 0:\n",
    "              this_resp = np.array([resp[t,0], t])\n",
    "              resp_mat = np.vstack((resp_mat, this_resp))   \n",
    "              cue_mat = np.vstack((cue_mat, last_cue))\n",
    "\n",
    "              break\n",
    "\n",
    "            elif not np.any(resp[t:i+2000]):\n",
    "              for t_a in range(i+2000,i+4000):\n",
    "                if resp[t_a] != 0:\n",
    "                  # print(i+2000, i+4000)\n",
    "                  # print(t_a)\n",
    "                  this_resp = np.array([resp[t_a,0], t-a])\n",
    "                  resp_mat = np.vstack((resp_mat, this_resp)) \n",
    "                  cue_mat = np.vstack((cue_mat, last_cue))  \n",
    "                break\n",
    "              break\n",
    "\n",
    "\n",
    "# if there is no response inside, we need to check the interval\n",
    "\n",
    "  return cue_mat[1:,:], resp_mat[1:,:]\n",
    "\n",
    "cue_mat, resp_mat = trail_extract(cue, resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d443a5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 3)\n"
     ]
    }
   ],
   "source": [
    "print(cue_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f152af9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# correct & wrong extraction\n",
    "a = 0\n",
    "\n",
    "# print(cue_mat.shape)\n",
    "# print(resp_mat.shape)\n",
    "\n",
    "wrong_trial = np.append(cue_mat[0,:], resp_mat[0,:])\n",
    "correct_trial = np.append(cue_mat[0,:], resp_mat[0,:])\n",
    "label = np.empty([len(resp_mat)]) \n",
    "\n",
    "for i in range(0,resp_mat.shape[0]):\n",
    "  if cue_mat[i,0] != resp_mat[i,0]:\n",
    "    new_wrong = np.append(cue_mat[i,:], resp_mat[i,:])\n",
    "    wrong_trial = np.vstack((wrong_trial, new_wrong))\n",
    "    label[i] = 1\n",
    "    a += 1\n",
    "  else:\n",
    "    new_correct = np.append(cue_mat[i,:], resp_mat[i,:])\n",
    "    correct_trial = np.vstack((correct_trial, new_correct))\n",
    "    label[i] = 0\n",
    "\n",
    "wrong_trial = wrong_trial[1:]\n",
    "correct_trial = correct_trial[1:]\n",
    "\n",
    "rt_wrong = wrong_trial[:,4] - wrong_trial[:,1]\n",
    "rt_correct = correct_trial[:,4] - correct_trial[:,1]\n",
    "\n",
    "# print(wrong_trial[:3])\n",
    "# print(correct_trial[:3])\n",
    "# print(rt_correct)\n",
    "# print(correct_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49a5cf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     5   7080  11080]\n",
      " [     5  11080  15080]\n",
      " [     5  15080  19080]\n",
      " [     1  19080  23080]\n",
      " [     5  23080  27080]\n",
      " [     2  27080  31080]\n",
      " [     3  31080  35080]\n",
      " [     4  35080  39080]\n",
      " [     1  39080  43080]\n",
      " [     1  43080  47080]\n",
      " [     1  47080  51080]\n",
      " [     5  51080  55080]\n",
      " [     2  55080  59080]\n",
      " [     4  59080  63080]\n",
      " [     3  63080  67080]\n",
      " [     2  67080  71080]\n",
      " [     3  71080  75080]\n",
      " [     5  75080  79080]\n",
      " [     2  79080  83080]\n",
      " [     2  83080  87080]\n",
      " [     1  91080  95080]\n",
      " [     4  95080  99080]\n",
      " [     3  99080 103080]\n",
      " [     1 103080 107080]\n",
      " [     4 107080 111080]\n",
      " [     1 111080 115080]\n",
      " [     3 115080 119080]\n",
      " [     3 119080 123080]\n",
      " [     1 123080 127080]\n",
      " [     4 127080 131080]\n",
      " [     2 131080 135080]\n",
      " [     3 135080 139080]\n",
      " [     5 139080 143080]\n",
      " [     2 143080 147080]\n",
      " [     5 147080 151080]\n",
      " [     4 151080 155080]\n",
      " [     4 155080 159080]\n",
      " [     3 159080 163080]\n",
      " [     2 163080 167080]\n",
      " [     3 167080 171080]\n",
      " [     1 175080 179080]\n",
      " [     5 179080 183080]\n",
      " [     2 183080 187080]\n",
      " [     3 187080 191080]\n",
      " [     3 191080 195080]\n",
      " [     5 195080 199080]\n",
      " [     2 199080 203080]\n",
      " [     3 203080 207080]\n",
      " [     1 207080 211080]\n",
      " [     1 211080 215080]\n",
      " [     3 215080 219080]\n",
      " [     5 219080 223080]\n",
      " [     3 223080 227080]\n",
      " [     2 227080 231080]\n",
      " [     4 231080 235080]\n",
      " [     2 235080 239080]\n",
      " [     2 239080 243080]\n",
      " [     1 243080 247080]\n",
      " [     5 247080 251080]\n",
      " [     3 251080 255080]\n",
      " [     4 255080 259080]\n",
      " [     3 259080 263080]\n",
      " [     2 263080 267080]\n",
      " [     4 267080 271080]\n",
      " [     3 271080 275080]\n",
      " [     1 275080 279080]\n",
      " [     1 279080 283080]\n",
      " [     2 283080 287080]\n",
      " [     1 287080 291080]\n",
      " [     4 291080 295080]\n",
      " [     4 295080 299080]\n",
      " [     5 299080 303080]\n",
      " [     3 303080 307080]\n",
      " [     4 307080 311080]\n",
      " [     3 311080 315080]\n",
      " [     1 315080 319080]\n",
      " [     2 319080 323080]\n",
      " [     4 323080 327080]\n",
      " [     3 327080 331080]\n",
      " [     4 331080 335080]\n",
      " [     2 335080 339080]\n",
      " [     1 339080 343080]\n",
      " [     1 343080 347080]\n",
      " [     2 347080 351080]\n",
      " [     3 351080 355080]\n",
      " [     3 355080 359080]\n",
      " [     4 359080 363080]\n",
      " [     5 363080 367080]\n",
      " [     1 367080 371080]\n",
      " [     3 371080 375080]\n",
      " [     3 375080 379080]\n",
      " [     2 379080 383080]\n",
      " [     5 383080 387080]\n",
      " [     5 387080 391080]\n",
      " [     3 391080 395080]\n",
      " [     3 395080 399080]\n",
      " [     1 399080 403080]\n",
      " [     2 407080 411080]\n",
      " [     3 411080 415080]\n",
      " [     5 415080 419080]\n",
      " [     4 419080 423080]\n",
      " [     5 423080 427080]\n",
      " [     2 427080 431080]\n",
      " [     2 435080 439080]\n",
      " [     1 439080 443080]\n",
      " [     5 443080 447080]\n",
      " [     4 447080 451080]\n",
      " [     5 451080 455080]\n",
      " [     5 455080 459080]\n",
      " [     4 459080 463080]\n",
      " [     4 463080 467080]\n",
      " [     5 467080 471080]\n",
      " [     4 475080 479080]\n",
      " [     4 479080 483080]\n",
      " [     5 483080 487080]\n",
      " [     5 487080 491080]\n",
      " [     4 491080 495080]\n",
      " [     1 495080 499080]\n",
      " [     1 499080 503080]\n",
      " [     2 503080 507080]\n",
      " [     3 507080 511080]\n",
      " [     5 511080 515080]\n",
      " [     1 515080 519080]\n",
      " [     2 519080 523080]\n",
      " [     3 523080 527080]\n",
      " [     5 527080 531080]\n",
      " [     5 531080 535080]\n",
      " [     1 535080 539080]\n",
      " [     1 539080 543080]\n",
      " [     4 547080 551080]\n",
      " [     1 551080 555080]\n",
      " [     1 559080 563080]\n",
      " [     4 563080 567080]\n",
      " [     2 567080 571080]\n",
      " [     5 571080 575080]\n",
      " [     3 575080 579080]\n",
      " [     1 579080 583080]\n",
      " [     4 583080 587080]\n",
      " [     2 587080 591080]\n",
      " [     2 591080 595080]\n",
      " [     2 595080 599080]\n",
      " [     4 599080 603080]\n",
      " [     4 603080 607080]]\n",
      "(143, 2)\n"
     ]
    }
   ],
   "source": [
    "# correct trails' cue and resp array\n",
    "c_cue = correct_trial[:,0:3]\n",
    "c_resp = correct_trial[:,3:len(correct_trial)]\n",
    "print(c_cue)\n",
    "print(c_resp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "fc0ab088",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CueOnset RespOnset\n"
     ]
    }
   ],
   "source": [
    "#trails for each finger extraction\n",
    "print('CueOnset','RespOnset')\n",
    "def finger(value):\n",
    "    #input: 1-5\n",
    "    #output: finger mat with relevant cue and resp mat data + diff calculation \n",
    "#     finger_mat = [0,0,0,0] #fake first row\n",
    "#     finger_mat = [0,0,0,0,0,0]\n",
    "#     print('Finger','CueOnset','EPE','Finger','RespOnset','RT')\n",
    "    #EPE = effective period end\n",
    "    \n",
    "    onset_c_finger = [0,0] \n",
    "    \n",
    "    for i in range(len(c_cue)):\n",
    "      if c_cue[i][0]==value:\n",
    "        c_row = c_cue[i]\n",
    "        r_row = c_resp[i]\n",
    "#         diff = c_resp[i][1] - c_cue[i][1]\n",
    "        row = np.concatenate((c_row[1],r_row[1]),axis=None)\n",
    "        onset_c_finger = np.vstack((onset_c_finger,row))\n",
    "    onset_c_finger = np.delete(onset_c_finger, 0, 0)\n",
    "    \n",
    "#         row = np.concatenate((c_row,r_row,diff),axis=None)\n",
    "#         finger_mat=np.vstack((finger_mat,row))\n",
    "#     finger_mat=np.delete(finger_mat, 0, 0)\n",
    "    return onset_c_finger\n",
    "\n",
    "# print(finger(1))\n",
    "# print(finger(2).shape)\n",
    "# print(finger(3).shape)\n",
    "# print(finger(4).shape)\n",
    "# print(finger(5).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f3044ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1172,  822,  610,  812,  894,  828,  811,  795,  861, 1109, 1060,\n",
       "        993, 1324,  911, 1093,  894,  828,  713,  712,  861,  564, 1307,\n",
       "        977,  960,  778,  779,  944,  911])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RT for each finger\n",
    "rt_f1 = finger(1)[:,1] - finger(1)[:,0]\n",
    "rt_f2 = finger(2)[:,1] - finger(2)[:,0]\n",
    "rt_f3 = finger(3)[:,1] - finger(3)[:,0]\n",
    "rt_f4 = finger(4)[:,1] - finger(4)[:,0]\n",
    "rt_f5 = finger(5)[:,1] - finger(5)[:,0]\n",
    "\n",
    "# plt.plot(rt_f1)\n",
    "# plt.plot(rt_f2)\n",
    "# plt.plot(rt_f3)\n",
    "# plt.plot(rt_f4)\n",
    "# plt.plot(rt_f5)\n",
    "# plt.legend(['Thumb', 'Index', 'Middle', 'Fourth', 'Little'])\n",
    "# plt.title('Response Time')\n",
    "# plt.show()\n",
    "\n",
    "rt_f5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d22412c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CueOnset RespOnset\n"
     ]
    }
   ],
   "source": [
    "#trails for each finger extraction 2\n",
    "print('CueOnset','RespOnset')\n",
    "def fingerflex(value):\n",
    "    #input: 1-5\n",
    "    #output: finger mat with relevant cue and resp mat data + diff calculation \n",
    "#     finger_mat = [0,0,0,0] #fake first row\n",
    "    finger_mat = [0,0]\n",
    "#     print('Finger','CueOnset','EPE','Finger','RespOnset','RT')\n",
    "    #EPE = effective period end\n",
    "    \n",
    "#     onset_c_finger = [0,0] \n",
    "    \n",
    "    for i in range(len(c_cue)):\n",
    "      if c_cue[i][0]==value:\n",
    "        c_row = c_cue[i]\n",
    "        r_row = c_resp[i]\n",
    "#         diff = c_resp[i][1] - c_cue[i][1]\n",
    "#         row = np.concatenate((c_row[1],r_row[1]),axis=None)\n",
    "#         onset_c_finger = np.vstack((onset_c_finger,row))\n",
    "#     onset_c_finger = np.delete(onset_c_finger, 0, 0)\n",
    "    \n",
    "        row = np.concatenate((c_row[1], c_row[0]),axis=None)\n",
    "        finger_mat=np.vstack((finger_mat,row))\n",
    "    finger_mat=np.delete(finger_mat, 0, 0)\n",
    "    return finger_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "84e12554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# events extraction for eeglab\n",
    "event_f1=fingerflex(1)\n",
    "events_f1 = np.column_stack((event_f1[:,0], np.full((len(event_f1), 1), 'cue'), event_f1[:,1]))\n",
    "events_f1\n",
    "with open(\"event_f1.txt\", \"w\") as o:\n",
    "    for line in events_f1:\n",
    "        print(\"{} {} {}\".format(line[0], line[1], line[2]), file=o)\n",
    "        \n",
    "event_f2=fingerflex(2)\n",
    "events_f2 = np.column_stack((event_f2[:,0], np.full((len(event_f2), 1), 'cue'), event_f2[:,1]))\n",
    "events_f2\n",
    "with open(\"event_f2.txt\", \"w\") as o:\n",
    "    for line in events_f2:\n",
    "        print(\"{} {} {}\".format(line[0], line[1], line[2]), file=o)\n",
    "        \n",
    "event_f3=fingerflex(3)\n",
    "events_f3 = np.column_stack((event_f3[:,0], np.full((len(event_f3), 1), 'cue'), event_f3[:,1]))\n",
    "events_f3\n",
    "with open(\"event_f3.txt\", \"w\") as o:\n",
    "    for line in events_f3:\n",
    "        print(\"{} {} {}\".format(line[0], line[1], line[2]), file=o)\n",
    "        \n",
    "event_f4=fingerflex(4)\n",
    "events_f4 = np.column_stack((event_f4[:,0], np.full((len(event_f4), 1), 'cue'), event_f4[:,1]))\n",
    "events_f4\n",
    "with open(\"event_f4.txt\", \"w\") as o:\n",
    "    for line in events_f4:\n",
    "        print(\"{} {} {}\".format(line[0], line[1], line[2]), file=o)\n",
    "        \n",
    "event_f5=fingerflex(5)\n",
    "events_f5 = np.column_stack((event_f5[:,0], np.full((len(event_f5), 1), 'cue'), event_f5[:,1]))\n",
    "events_f5\n",
    "with open(\"event_f5.txt\", \"w\") as o:\n",
    "    for line in events_f5:\n",
    "        print(\"{} {} {}\".format(line[0], line[1], line[2]), file=o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3497cc2c",
   "metadata": {},
   "source": [
    "# PSD-freq and RT correlation for each finger flexion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c11cdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal as signal\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e6dbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecog_region(region_index, ecog):\n",
    "  # 1: dorsal m1, 3: dorsal s1, 4: ventral sensorimotor (m1+s1)\n",
    "  # 6: frontal (higher cognitive functions such as memory, emotions, impulse control, problem solving, social interaction, and motor function); \n",
    "  # 7: parietal (process sensory info), \n",
    "  # 8:temporal (object recognition, interact to creat new and long term memories), 9: occipital (visual perception)\n",
    "#   print(elect_region)\n",
    "  region = np.where(elect_region == region_index)[0]\n",
    "\n",
    "  region_ecog = ecog[region]\n",
    "\n",
    "  return region, region_ecog\n",
    "print(ecog_region(1,ecog1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548eb269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_c_extraction(elec_list, ecog_elec):\n",
    "\n",
    "  ecog_wrong = np.empty([a,len(elec_list),2000])\n",
    "  ecog_correct = np.empty([resp_mat.shape[0] - a,len(elec_list),2000])  \n",
    "\n",
    "\n",
    "  for i in range(0,wrong_trial.shape[0]):\n",
    "    onset_t = wrong_trial[i,1]\n",
    "    # offset_t = onset_t + 2000\n",
    "    ecog_wrong[i] = ecog_elec[:,onset_t:onset_t+2000]\n",
    "    \n",
    "\n",
    "  for i in range(0,correct_trial.shape[0]):\n",
    "    onset_t = correct_trial[i,1] \n",
    "    # offset_t = onset_t + 2000\n",
    "    ecog_correct[i] = ecog_elec[:,onset_t:onset_t+2000]\n",
    "\n",
    "  return ecog_wrong, ecog_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4936229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psd_calculation(ecog_wrong, ecog_correct):\n",
    "\n",
    "  w_f, wrong_psd = signal.welch(ecog_wrong, fs = 1000, nperseg= 1024, noverlap = 1024//2)\n",
    "  c_f, correct_psd = signal.welch(ecog_correct, fs = 1000, nperseg= 1024, noverlap = 1024//2)\n",
    "\n",
    "\n",
    "  # alpha_index = np.where((w_f<25) & (w_f>13))[0]\n",
    "\n",
    "  # w_f = w_f[alpha_index]\n",
    "  # c_f = c_f[alpha_index]\n",
    "\n",
    "  # wrong_psd = wrong_psd[:,:,alpha_index]\n",
    "  # correct_psd = correct_psd[:,:,alpha_index]\n",
    "\n",
    "  wrong_psd = 10*np.log10(wrong_psd)\n",
    "  wrong_psd_ave = np.mean(wrong_psd, axis = 0)\n",
    "  correct_psd = 10*np.log10(correct_psd)\n",
    "  correct_psd_ave = np.mean(correct_psd, axis = 0)\n",
    "  \n",
    "  return w_f, wrong_psd_ave, correct_psd_ave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be657382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psd_extraction(index, ecog):\n",
    "\n",
    "  elec, ecog = ecog_region(index, ecog)\n",
    "\n",
    "  ecog_wrong, ecog_correct = w_c_extraction(elec, ecog)\n",
    "\n",
    "  f, wrong_psd, correct_psd = psd_calculation(ecog_wrong, ecog_correct)\n",
    "\n",
    "  return f, wrong_psd, correct_psd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0d9cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_list = [1,4,6,7,8,9]\n",
    "f,_,_ = psd_extraction(region_list[1], ecog)\n",
    "diff_psd = np.empty([len(region_list),len(f)])\n",
    "\n",
    "for i in range(len(region_list)):\n",
    "  f, wrong_psd, correct_psd = psd_extraction(region_list[i], ecog)\n",
    "  plt.plot(f, wrong_psd-correct_psd)\n",
    "  diff_psd[i] = wrong_psd-correct_psd\n",
    "\n",
    "plt.legend(['dorsal M1', 'ventral sensorimotor (M1+S1)', 'frontal', 'parietal','temporal','occipital'])\n",
    "plt.title('alpha ocssilation')\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD [dB]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1a2e89",
   "metadata": {},
   "source": [
    "# Motor preparation pattern examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "acae26b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1870\n"
     ]
    }
   ],
   "source": [
    "# minimum RT extraction\n",
    "rt_all = correct_trial[:,4] - correct_trial[:,1]\n",
    "rtmin_all = rt_all.min()\n",
    "print(rtmin_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7319af0",
   "metadata": {},
   "source": [
    "Construct epochs based on rt_all.min and respOnset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1568c6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# events creation for mne\n",
    "event_id = {\n",
    "    'Thumb': 1,\n",
    "    'Index': 2, \n",
    "    'Middle': 3, \n",
    "    'Fourth': 4,\n",
    "    'Little': 5\n",
    "}\n",
    "\n",
    "array_0 = np.zeros((len(correct_trial),1))\n",
    "array_0.dtype\n",
    "\n",
    "events = np.column_stack((correct_trial[:,4], array_0, correct_trial[:,3]))\n",
    "# events=events.astype(np.uint8)\n",
    "events.dtype\n",
    "events = events.astype('int')\n",
    "# raw_notch.plot(events=events, event_id=event_id)\n",
    "# plt.show\n",
    "\n",
    "metadata, events, event_id = mne.epochs.make_metadata(\n",
    "    events=all_events, event_id=all_event_id,\n",
    "    tmin=metadata_tmin, tmax=metadata_tmax, sfreq=raw_notch.info['sfreq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "de987574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt2array(txt_path, delimiter):\n",
    "    #---\n",
    "    # 功能：读取只包含数字的txt文件，并转化为array形式\n",
    "    # txt_path：txt的路径；delimiter：数据之间的分隔符\n",
    "    #---\n",
    "    data_list = []\n",
    "    with open(txt_path) as f:\n",
    "        data = f.readlines()\n",
    "    for line in data:\n",
    "        line = line.strip(\"\\n\")  # 去除末尾的换行符\n",
    "        data_split = line.split(delimiter)\n",
    "        temp = list(map(float, data_split))\n",
    "        data_list.append(temp)\n",
    "\n",
    "    data_array = np.array(data_list)\n",
    "    return data_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "bea6e6d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'string' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [140]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     aa[i]\u001b[38;5;241m.\u001b[39mappend(i)\n\u001b[0;32m      8\u001b[0m bb\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(aa)\n\u001b[1;32m---> 10\u001b[0m locs_bp_mat\u001b[38;5;241m=\u001b[39m\u001b[43mtxt2array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:/Users/Lenovo/mne/locs_bp.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m locs_new\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mcolumn_stack((bb, locs_bp, bb))\n\u001b[0;32m     12\u001b[0m locs_new\n",
      "Input \u001b[1;32mIn [139]\u001b[0m, in \u001b[0;36mtxt2array\u001b[1;34m(txt_path, delimiter)\u001b[0m\n\u001b[0;32m     10\u001b[0m     line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# 去除末尾的换行符\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     data_split \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(delimiter)\n\u001b[1;32m---> 12\u001b[0m     temp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[43mstring\u001b[49m, data_split))\n\u001b[0;32m     13\u001b[0m     data_list\u001b[38;5;241m.\u001b[39mappend(temp)\n\u001b[0;32m     15\u001b[0m data_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data_list)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'string' is not defined"
     ]
    }
   ],
   "source": [
    "# locs for eeglab\n",
    "\n",
    "aa=[]\n",
    "for i in range(46):\n",
    "  aa.append([])\n",
    "  for j in range(1):\n",
    "    aa[i].append(i)\n",
    "bb=np.array(aa)\n",
    "\n",
    "locs_bp_mat=txt2array('C:/Users/Lenovo/mne/locs_bp.txt',' ')\n",
    "locs_new=np.column_stack((bb, locs_bp, bb))\n",
    "locs_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4cd5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#events distribution\n",
    "mne.viz.plot_events(events)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50689b9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# epochs creation for mne\n",
    "\n",
    "rtmin_epochs = mne.Epochs(raw_notch, \n",
    "#                                info,\n",
    "                               tmin=-rtmin_all,\n",
    "#                                preload=True,\n",
    "                               events=events, \n",
    "                               event_id=event_id,\n",
    "                         preload=True)\n",
    "rtmin_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0e317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtmin_epochs.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf22e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as pyplt\n",
    "# fig,ax = pyplt.subplots(2)\n",
    "\n",
    "matplotlib.use('Qt5Agg')\n",
    "raw_notch.plot_psd()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
